{
  "paragraphs": [
    {
      "text": "%md\n# NCATS Translator Blackboard\n\n### Overview\nThis note explores methods for combining resources within the [RENCI data](https://mesostars.wordpress.com/) lake. These resources pair data with the technologies best suited to manage them. Graph oriented semantic web data is housed in scalable graph databases. Environmental exposure data is housed in a GIS oriented relational store. In front of it all, we have a Zeppelin notebook interfacing to Apache Spark.\n\nThis notebook is also the workspace for addressing the NCATS Translator Green Team Blackboard described in this [GitHub Issue](https://github.com/ResearchSoftwareInstitute/greendatatranslator/issues/15).\nUsing these resources, we\u0027ll attempt the following tasks:\n\u003e* List medications for a disease (in our case asthma) \n\u003e* List protein targets for a list of medications\n\u003e* List biological pathways for a list of protein targets\n\u003e* List initiating mechanisms (e.g., molecular initiative events) for PM2.5 and ozone\n\u003e* List targets affected by asthma initiating events and whether the interaction is activation or inhibition\n\u003e* List genes associated with up and down regulation of targets from 5\n\n### Data Sources\nHere are the initial data sources we\u0027ll be integrating:\n\n| Source        | Stack                  | Description                   |\n|---------------|:----------------------:|-------------------------------|\n| Blackboard    | Apache Spark/Zeppelin  | Data Parallel Compute / Python|\n| Chem2Bio2RDF  | Blazegraph             | Graph Database / SPARQL       |\n| Monarch       | Blazegraph             | Graph Database / SPARQL       |\n| Monarch       | SmartAPI               | Swagger/smartAPI REST service |\n| Environmental | PostgreSQL / PostGIS   | Relational GIS Database / SQL |\n| WikiPathways  | Virtuoso               | Public SPARQL Endpoint        |\n\n\n### Approach\n\nTo start with, we\u0027ll do some environmental setup, including:\n\n* **Setup**\n    * Import Python libraries for templating and invoking SPARQL endpoints\n    * Configure our HTTP proxy\n    * Provide a function for calling a SPARQL endpoint\n* **Query 1** : List medications for a disease\n    * Query RENCI\u0027s Blazegraph store via the chem2bio2rdf schema\n* **Query 2** : List protein targets for a list of medications\n    * Chem2bio2rdf again\n    * Graph results via Seaborn\n* **Query 3** : List biological pathways for a list of protein targets\n    * Try Monarch Initiative SmartAPI\n    * Fallback to WikiPathways SPARQL query for now",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:21:26 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/markdown",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eNCATS Translator Blackboard\u003c/h1\u003e\n\u003ch3\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThis note explores methods for combining resources within the \u003ca href\u003d\"https://mesostars.wordpress.com/\"\u003eRENCI data\u003c/a\u003e lake. These resources pair data with the technologies best suited to manage them. Graph oriented semantic web data is housed in scalable graph databases. Environmental exposure data is housed in a GIS oriented relational store. In front of it all, we have a Zeppelin notebook interfacing to Apache Spark.\u003c/p\u003e\n\u003cp\u003eThis notebook is also the workspace for addressing the NCATS Translator Green Team Blackboard described in this \u003ca href\u003d\"https://github.com/ResearchSoftwareInstitute/greendatatranslator/issues/15\"\u003eGitHub Issue\u003c/a\u003e.\u003cbr/\u003eUsing these resources, we\u0026rsquo;ll attempt the following tasks:\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cul\u003e\n    \u003cli\u003eList medications for a disease (in our case asthma)\u003c/li\u003e\n    \u003cli\u003eList protein targets for a list of medications\u003c/li\u003e\n    \u003cli\u003eList biological pathways for a list of protein targets\u003c/li\u003e\n    \u003cli\u003eList initiating mechanisms (e.g., molecular initiative events) for PM2.5 and ozone\u003c/li\u003e\n    \u003cli\u003eList targets affected by asthma initiating events and whether the interaction is activation or inhibition\u003c/li\u003e\n    \u003cli\u003eList genes associated with up and down regulation of targets from 5\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eData Sources\u003c/h3\u003e\n\u003cp\u003eHere are the initial data sources we\u0026rsquo;ll be integrating:\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n    \u003ctr\u003e\n      \u003cth\u003eSource \u003c/th\u003e\n      \u003cth align\u003d\"center\"\u003eStack \u003c/th\u003e\n      \u003cth\u003eDescription \u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eBlackboard \u003c/td\u003e\n      \u003ctd align\u003d\"center\"\u003eApache Spark/Zeppelin \u003c/td\u003e\n      \u003ctd\u003eData Parallel Compute / Python\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eChem2Bio2RDF \u003c/td\u003e\n      \u003ctd align\u003d\"center\"\u003eBlazegraph \u003c/td\u003e\n      \u003ctd\u003eGraph Database / SPARQL \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eMonarch \u003c/td\u003e\n      \u003ctd align\u003d\"center\"\u003eBlazegraph \u003c/td\u003e\n      \u003ctd\u003eGraph Database / SPARQL \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eMonarch \u003c/td\u003e\n      \u003ctd align\u003d\"center\"\u003eSmartAPI \u003c/td\u003e\n      \u003ctd\u003eSwagger/smartAPI REST service \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eEnvironmental \u003c/td\u003e\n      \u003ctd align\u003d\"center\"\u003ePostgreSQL / PostGIS \u003c/td\u003e\n      \u003ctd\u003eRelational GIS Database / SQL \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eWikiPathways \u003c/td\u003e\n      \u003ctd align\u003d\"center\"\u003eVirtuoso \u003c/td\u003e\n      \u003ctd\u003ePublic SPARQL Endpoint \u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eApproach\u003c/h3\u003e\n\u003cp\u003eTo start with, we\u0026rsquo;ll do some environmental setup, including:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003cstrong\u003eSetup\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003eImport Python libraries for templating and invoking SPARQL endpoints\u003c/li\u003e\n      \u003cli\u003eConfigure our HTTP proxy\u003c/li\u003e\n      \u003cli\u003eProvide a function for calling a SPARQL endpoint\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eQuery 1\u003c/strong\u003e : List medications for a disease\n    \u003cul\u003e\n      \u003cli\u003eQuery RENCI\u0026rsquo;s Blazegraph store via the chem2bio2rdf schema\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eQuery 2\u003c/strong\u003e : List protein targets for a list of medications\n    \u003cul\u003e\n      \u003cli\u003eChem2bio2rdf again\u003c/li\u003e\n      \u003cli\u003eGraph results via Seaborn\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eQuery 3\u003c/strong\u003e : List biological pathways for a list of protein targets\n    \u003cul\u003e\n      \u003cli\u003eTry Monarch Initiative SmartAPI\u003c/li\u003e\n      \u003cli\u003eFallback to WikiPathways SPARQL query for now\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872576_874864018",
      "id": "20170220-204952_812620537",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:21:26 PM",
      "dateFinished": "Mar 10, 2017 2:21:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom string import Template\nfrom collections import defaultdict\nfrom SPARQLWrapper import SPARQLWrapper2, JSON\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport urllib2\nproxy \u003d urllib2.ProxyHandler({\u0027http\u0027: \u0027gateway.ad.renci.org:8080\u0027})\nopener \u003d urllib2.build_opener(proxy)\nurllib2.install_opener(opener)\n\nblazegraph_uri \u003d \"http://stars-blazegraph.renci.org/bigdata/sparql\"\nblazegraph \u003d SPARQLWrapper2 (blazegraph_uri)\ndef query_sparql (query, service\u003dblazegraph):\n    service.setQuery (query)\n    service.setReturnFormat (JSON)\n    return service.query().convert ()\n",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 3:53:08 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/python",
        "results": {},
        "editorHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1488943872577_874479270",
      "id": "20170220-205005_1359367316",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 3:53:08 PM",
      "dateFinished": "Mar 10, 2017 3:53:10 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 1. List medications by disease:\nFirst, define a SPARQL query as a template allowing us to filter by disease name.\n\nIt considers DrugBank and OMIM data sets from Chem2Bio2RDF",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 3:52:43 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/markdown",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e1. List medications by disease:\u003c/h3\u003e\n\u003cp\u003eFirst, define a SPARQL query as a template allowing us to filter by disease name.\u003c/p\u003e\n\u003cp\u003eIt considers DrugBank and OMIM data sets from Chem2Bio2RDF\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872578_875633516",
      "id": "20170220-205021_804465188",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 3:52:43 PM",
      "dateFinished": "Mar 10, 2017 3:52:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nquery \u003d Template (\"\"\"\nPREFIX db_resource: \u003chttp://chem2bio2rdf.org/drugbank/resource/\u003e\nPREFIX omim:        \u003chttp://chem2bio2rdf.org/omim/resource/\u003e\nSELECT DISTINCT ?disease ?generic_name\nWHERE {\n  ?drug        db_resource:Generic_Name ?generic_name .\n  ?disease_rec omim:drug                ?drug ;\n               omim:Name                ?disease .\n  FILTER regex(?disease, \"${disease}\", \"i\")\n}\"\"\")\nresults \u003d query_sparql (query.substitute (disease\u003d\"asthma\"))\nprint (map (lambda b : b[\u0027generic_name\u0027].value, results.bindings))",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 3:53:14 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/python",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[u\u0027Dyphylline\u0027, u\u0027Hydrocortisone\u0027, u\u0027Salmeterol\u0027, u\u0027Formoterol\u0027, u\u0027Theophylline\u0027, u\u0027Beclomethasone\u0027, u\u0027Montelukast\u0027, u\u0027Fluticasone Propionate\u0027, u\u0027Chlorpheniramine\u0027, u\u0027Aminophylline\u0027, u\u0027Vitamin E\u0027, u\u0027Flunisolide\u0027, u\u0027Isoetharine\u0027, u\u0027Omalizumab\u0027, u\u0027Nedocromil\u0027, u\u0027Zileuton\u0027, u\u0027Mometasone\u0027, u\u0027Enprofylline\u0027, u\u0027Isoproterenol\u0027, u\u0027Zafirlukast\u0027, u\u0027Cinalukast\u0027, u\u0027Terbutaline\u0027]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872579_875248767",
      "id": "20170220-205037_1655435298",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 3:53:14 PM",
      "dateFinished": "Mar 10, 2017 3:53:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### 2. List of Gene Targets for a set of drugs:\n\nThis is a count of protein targets by drug. It\u0027s generated by a Zeppelin notebook running on RENCI\u0027s Stars big data infrastructure.\nThe Zeppelin notebook is connected to an Apache Spark Python interpreter running on the Stars distributed Mesos compute fabric.\n\nThis text is generated by a Zeppelin markdown note. The graphic below is generated by a second Zeppelin PySpark note. The PySpark note creates a SPARQL query which it executes on a Blazegraph graph database instance.\n\nThe Blazegraph\tinstance contains several Semantic Web artifacts from the Chem2Bio2RDF project.\nProtein targets associated with each drug are counted and rendered in the following histogram using Seaborn and Matplotlib.",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:20:09 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/markdown",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e2. List of Gene Targets for a set of drugs:\u003c/h3\u003e\n\u003cp\u003eThis is a count of protein targets by drug. It\u0026rsquo;s generated by a Zeppelin notebook running on RENCI\u0026rsquo;s Stars big data infrastructure.\u003cbr/\u003eThe Zeppelin notebook is connected to an Apache Spark Python interpreter running on the Stars distributed Mesos compute fabric.\u003c/p\u003e\n\u003cp\u003eThis text is generated by a Zeppelin markdown note. The graphic below is generated by a second Zeppelin PySpark note. The PySpark note creates a SPARQL query which it executes on a Blazegraph graph database instance.\u003c/p\u003e\n\u003cp\u003eThe Blazegraph instance contains several Semantic Web artifacts from the Chem2Bio2RDF project.\u003cbr/\u003eProtein targets associated with each drug are counted and rendered in the following histogram using Seaborn and Matplotlib.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872580_873325023",
      "id": "20170220-205103_421037077",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:20:11 PM",
      "dateFinished": "Mar 10, 2017 2:20:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\nquery \u003d Template (\"\"\"\nPREFIX db_resource: \u003chttp://chem2bio2rdf.org/drugbank/resource/\u003e\nSELECT ?generic_name ?protein\nWHERE {\n  ?interaction db_resource:SwissProt_ID ?protein .\n  ?interaction db_resource:DBID         ?drug .\n  ?drug        db_resource:Generic_Name ?generic_name .\n  FILTER regex(?generic_name, \"${drugs}\", \"i\")\n}\"\"\")\ndrug_protein \u003d defaultdict(list)\nprotein_drug \u003d defaultdict(list)\ndrug_list \u003d \"Creatine|Baclofen|Amlodipine|Brimonidine|Acetaminophen|Aspirin\"\nresults \u003d query_sparql (query.substitute (drugs\u003ddrug_list))\nfor bind in results.bindings:\n    drug \u003d bind[\u0027generic_name\u0027].value\n    protein \u003d bind[\u0027protein\u0027].value.rsplit(\u0027/\u0027, 1)[-1]\n    protein_drug[protein].append (drug)\n    drug_protein[drug].append (protein)\n\nx_labels \u003d drug_list.split (\"|\")\ndata\u003d{ \u0027x\u0027 : x_labels, \u0027y\u0027 : map (lambda k : len(drug_protein[k]), x_labels) }\nsns.set_style(\"whitegrid\")\nsns.plt.title(\u0027Protein Targets By Drug\u0027, weight\u003d\u0027bold\u0027).set_fontsize(\u002718\u0027)\nax \u003d sns.barplot(x\u003d\"x\", y\u003d\"y\", data\u003ddata). \\\n    set(xlabel\u003d\u0027Drug\u0027, ylabel\u003d\u0027#Protein Targets\u0027)\n",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:20:09 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/python",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv style\u003d\u0027width:auto;height:auto\u0027\u003e\u003cimg src\u003ddata:image/png;base64,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\u003d\u003d style\u003d\u0027width\u003dauto;height:auto\u0027\u003e\u003cdiv\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872581_872940274",
      "id": "20170220-205151_1129629826",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:20:14 PM",
      "dateFinished": "Mar 10, 2017 2:20:16 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Query 3: Find pathways for a given protein\n\nWe\u0027ll look at the Monarch Initiative\u0027s [SmartAPI](http://api.monarchinitiative.org/api/#!/bioentity/get_pathway_object) first:",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:20:09 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/markdown",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eQuery 3: Find pathways for a given protein\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll look at the Monarch Initiative\u0026rsquo;s \u003ca href\u003d\"http://api.monarchinitiative.org/api/#!/bioentity/get_pathway_object\"\u003eSmartAPI\u003c/a\u003e first:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872583_873709772",
      "id": "20170220-205207_1746444949",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:20:12 PM",
      "dateFinished": "Mar 10, 2017 2:20:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nimport requests\nproxies \u003d {\n  \u0027http\u0027: \u0027http://gateway.ad.renci.org:8080/\u0027,\n}\nmonarch_api_base \u003d \"http://api.monarchinitiative.org/api\"\nmonarch_api__bioentity_pathway \u003d \"{0}/bioentity/pathway\".format (monarch_api_base)\nuri \u003d \"{0}/GO:0005978\".format (monarch_api__bioentity_pathway)\nresp \u003d requests.get(\n    uri,\n    proxies\u003dproxies)\nif resp.status_code !\u003d 200:\n    raise ValueError(\u0027GET {} status: {}\u0027.format(uri, resp.status_code))\n\nprint(\u0027{}\u0027.format(resp.json()))",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:20:09 PM",
      "config": {
        "enabled": true,
        "tableHide": true,
        "editorMode": "ace/mode/python",
        "results": {},
        "editorHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3887908839584107827.py\", line 346, in \u003cmodule\u003e\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3887908839584107827.py\", line 334, in \u003cmodule\u003e\n    exec(code)\n  File \"\u003cstdin\u003e\", line 10, in \u003cmodule\u003e\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/api.py\", line 70, in get\n    return request(\u0027get\u0027, url, params\u003dparams, **kwargs)\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/api.py\", line 56, in request\n    return session.request(method\u003dmethod, url\u003durl, **kwargs)\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/sessions.py\", line 488, in request\n    resp \u003d self.send(prep, **send_kwargs)\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/sessions.py\", line 630, in send\n    history \u003d [resp for resp in gen] if allow_redirects else []\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/sessions.py\", line 190, in resolve_redirects\n    **adapter_kwargs\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/sessions.py\", line 609, in send\n    r \u003d adapter.send(request, **kwargs)\n  File \"/projects/stars/venv/lib/python2.7/site-packages/requests/adapters.py\", line 487, in send\n    raise ConnectionError(e, request\u003drequest)\nConnectionError: HTTPSConnectionPool(host\u003d\u0027api.monarchinitiative.org\u0027, port\u003d443): Max retries exceeded with url: /api/bioentity/pathway/GO:0005978 (Caused by NewConnectionError(\u0027\u003crequests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x544e050\u003e: Failed to establish a new connection: [Errno 110] Connection timed out\u0027,))\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872584_871786027",
      "id": "20170220-205331_987621401",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:20:15 PM",
      "dateFinished": "Mar 10, 2017 2:22:32 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nLooks like that functionality\u0027s still in development. Let\u0027s try [WikiPathways](http://www.wikipathways.org/index.php/WikiPathways) in the meantime:",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:20:09 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/markdown",
        "results": {},
        "editorHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eLooks like that functionality\u0026rsquo;s still in development. Let\u0026rsquo;s try \u003ca href\u003d\"http://www.wikipathways.org/index.php/WikiPathways\"\u003eWikiPathways\u003c/a\u003e in the meantime:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872585_871401278",
      "id": "20170220-205348_1942986158",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:20:12 PM",
      "dateFinished": "Mar 10, 2017 2:20:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nwikipathways_iri \u003d \"http://sparql.wikipathways.org/\"\nwikipathways \u003d SPARQLWrapper2 (wikipathways_iri)\nquery \u003d Template (\"\"\"\nPREFIX wp:      \u003chttp://vocabularies.wikipathways.org/wp#\u003e\nPREFIX rdfs:    \u003chttp://www.w3.org/2000/01/rdf-schema#\u003e\nPREFIX dcterms: \u003chttp://purl.org/dc/terms/\u003e\nSELECT DISTINCT ?pathway str(?label) as ?geneProduct\nWHERE {\n    ?geneProduct a wp:GeneProduct . \n    ?geneProduct rdfs:label ?label .\n    ?geneProduct dcterms:isPartOf ?pathway .\n    ?pathway a wp:Pathway .\n    FILTER regex(str(?label), \"${protein}\"). \n}\"\"\").substitute (protein\u003d\"CYP\")\nresults \u003d query_sparql (query \u003d query, service \u003d wikipathways)\n\npath_gene \u003d []\nfor binding in results.bindings:\n    path_gene.append ([ binding[\"pathway\"].value, binding[\"geneProduct\"].value])    \n\nr_path_gene \u003d sc.parallelize (path_gene)\ns_path_gene \u003d r_path_gene.\\\n    map (lambda p : ( p[0].split(\u0027/\u0027)[-1], 1 )). \\\n    reduceByKey (lambda x,y: x+y). \\\n    sortBy (lambda p : p[1], ascending\u003dFalse). \\\n    take (10)\n\nprint (\"Total path-gene pairs: {0}\".format (len(path_gene)))\nprint (\"Top 10 gene count:\")\nfor p in s_path_gene:\n    print (\"   -- {0}\".format (p))",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 3:53:32 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/python",
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 227.55209350585938,
              "optionOpen": false
            }
          }
        },
        "editorHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": true
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Total path-gene pairs: 684\nTop 10 gene count:\n   -- (u\u0027WP43_r84102\u0027, 60)\n   -- (u\u0027WP702_r73516\u0027, 55)\n   -- (u\u0027WP1077_r80775\u0027, 52)\n   -- (u\u0027WP1006_r80841\u0027, 51)\n   -- (u\u0027WP3248_r85056\u0027, 24)\n   -- (u\u0027WP981_r80762\u0027, 20)\n   -- (u\u0027WP3264_r80908\u0027, 16)\n   -- (u\u0027WP3131_r89204\u0027, 15)\n   -- (u\u0027WP299_r89331\u0027, 13)\n   -- (u\u0027WP970_r80700\u0027, 12)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872586_872555525",
      "id": "20170220-205406_1128585816",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 3:53:22 PM",
      "dateFinished": "Mar 10, 2017 3:53:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nimport os\nfrom subprocess import call\nscratch \u003d \"/home/evryscope/hive\"\nos.chdir (scratch)\n\ncall([\"pwd\"])\n\nfrom pyspark.sql.types import *\nschemaString \u003d \"path gene\"\nfields \u003d [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\nschema \u003d StructType(fields)\n\nsc.setLocalProperty (\"spark.sql.warehouse.dir\", scratch)\nsc.setLocalProperty (\"hive.metastore.warehouse.dir\", scratch)\nsc.getConf().set (\"spark.sql.warehouse.dir\", scratch)\nsc.getConf().set (\"hive.metastore.warehouse.dir\", scratch)\nr_path_gene.                               \\\n    toDF (schema).           \\\n    registerTempTable (\u0027pgene\u0027)\n",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 3:57:04 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n/home/evryscope/hive\n"
          },
          {
            "type": "TEXT",
            "data": "Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3024067490131316479.py\", line 346, in \u003cmodule\u003e\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3024067490131316479.py\", line 339, in \u003cmodule\u003e\n    exec(code)\n  File \"\u003cstdin\u003e\", line 15, in \u003cmodule\u003e\n  File \"/projects/stars/stack/spark/spark2/python/pyspark/sql/session.py\", line 57, in toDF\n    return sparkSession.createDataFrame(self, schema, sampleRatio)\n  File \"/projects/stars/stack/spark/spark2/python/pyspark/sql/session.py\", line 526, in createDataFrame\n    jdf \u003d self._jsparkSession.applySchemaToPythonRDD(jrdd.rdd(), schema.json())\n  File \"/projects/stars/stack/spark/spark2/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/projects/stars/stack/spark/spark2/python/pyspark/sql/utils.py\", line 63, in deco\n    return f(*a, **kw)\n  File \"/projects/stars/stack/spark/spark2/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py\", line 319, in get_return_value\n    format(target_id, \".\", name), value)\nPy4JJavaError: An error occurred while calling o54.applySchemaToPythonRDD.\n: java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.\u003cinit\u003e(HiveClientImpl.scala:189)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)\n\tat org.apache.spark.sql.hive.HiveSessionState$$anon$1.\u003cinit\u003e(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.\u003cinit\u003e(RetryingMetaStoreClient.java:86)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n\t... 32 more\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n\t... 38 more\nCaused by: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url \u003d jdbc:derby:;databaseName\u003dmetastore_db;create\u003dtrue, username \u003d APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\r\njava.sql.SQLException: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.\u003cinit\u003e(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:571)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:187)\n\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n\tat com.jolbox.bonecp.BoneCP.\u003cinit\u003e(BoneCP.java:416)\n\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n\tat org.datanucleus.store.rdbms.RDBMSStoreManager.\u003cinit\u003e(RDBMSStoreManager.java:298)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73)\n\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.\u003cinit\u003e(RawStoreProxy.java:57)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.\u003cinit\u003e(RetryingHMSHandler.java:66)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.\u003cinit\u003e(HiveMetaStoreClient.java:199)\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.\u003cinit\u003e(SessionHiveMetaStoreClient.java:74)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.\u003cinit\u003e(RetryingMetaStoreClient.java:86)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.\u003cinit\u003e(HiveClientImpl.scala:189)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)\n\tat org.apache.spark.sql.hive.HiveSessionState$$anon$1.\u003cinit\u003e(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: ERROR XJ041: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n\t... 100 more\nCaused by: ERROR XBM0H: Directory /metastore_db cannot be created.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n\t... 97 more\n------\r\n\nNestedThrowables:\njava.sql.SQLException: Unable to open a test connection to the given database. JDBC url \u003d jdbc:derby:;databaseName\u003dmetastore_db;create\u003dtrue, username \u003d APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\r\njava.sql.SQLException: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.\u003cinit\u003e(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:571)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:187)\n\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n\tat com.jolbox.bonecp.BoneCP.\u003cinit\u003e(BoneCP.java:416)\n\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n\tat org.datanucleus.store.rdbms.RDBMSStoreManager.\u003cinit\u003e(RDBMSStoreManager.java:298)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73)\n\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.\u003cinit\u003e(RawStoreProxy.java:57)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.\u003cinit\u003e(RetryingHMSHandler.java:66)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.\u003cinit\u003e(HiveMetaStoreClient.java:199)\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.\u003cinit\u003e(SessionHiveMetaStoreClient.java:74)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.\u003cinit\u003e(RetryingMetaStoreClient.java:86)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.\u003cinit\u003e(HiveClientImpl.scala:189)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)\n\tat org.apache.spark.sql.hive.HiveSessionState$$anon$1.\u003cinit\u003e(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: ERROR XJ041: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n\t... 100 more\nCaused by: ERROR XBM0H: Directory /metastore_db cannot be created.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n\t... 97 more\n------\r\n\n\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:436)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:788)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73)\n\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.\u003cinit\u003e(RawStoreProxy.java:57)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.\u003cinit\u003e(RetryingHMSHandler.java:66)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.\u003cinit\u003e(HiveMetaStoreClient.java:199)\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.\u003cinit\u003e(SessionHiveMetaStoreClient.java:74)\n\t... 43 more\nCaused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url \u003d jdbc:derby:;databaseName\u003dmetastore_db;create\u003dtrue, username \u003d APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\r\njava.sql.SQLException: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.\u003cinit\u003e(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:571)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:187)\n\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n\tat com.jolbox.bonecp.BoneCP.\u003cinit\u003e(BoneCP.java:416)\n\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n\tat org.datanucleus.store.rdbms.RDBMSStoreManager.\u003cinit\u003e(RDBMSStoreManager.java:298)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73)\n\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.\u003cinit\u003e(RawStoreProxy.java:57)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.\u003cinit\u003e(RetryingHMSHandler.java:66)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.\u003cinit\u003e(HiveMetaStoreClient.java:199)\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.\u003cinit\u003e(SessionHiveMetaStoreClient.java:74)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.\u003cinit\u003e(RetryingMetaStoreClient.java:86)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.\u003cinit\u003e(HiveClientImpl.scala:189)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)\n\tat org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)\n\tat org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)\n\tat org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)\n\tat org.apache.spark.sql.hive.HiveSessionState$$anon$1.\u003cinit\u003e(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)\n\tat org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)\n\tat org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: ERROR XJ041: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n\t... 100 more\nCaused by: ERROR XBM0H: Directory /metastore_db cannot be created.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n\t... 97 more\n------\r\n\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n\tat com.jolbox.bonecp.BoneCP.\u003cinit\u003e(BoneCP.java:422)\n\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n\tat org.datanucleus.store.rdbms.RDBMSStoreManager.\u003cinit\u003e(RDBMSStoreManager.java:298)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n\t... 72 more\nCaused by: java.sql.SQLException: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.\u003cinit\u003e(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:571)\n\tat java.sql.DriverManager.getConnection(DriverManager.java:187)\n\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n\tat com.jolbox.bonecp.BoneCP.\u003cinit\u003e(BoneCP.java:416)\n\t... 84 more\nCaused by: ERROR XJ041: Failed to create database \u0027metastore_db\u0027, see the next exception for details.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n\t... 100 more\nCaused by: ERROR XBM0H: Directory /metastore_db cannot be created.\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)\n\tat org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)\n\t... 97 more\n\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1489173547370_-783599109",
      "id": "20170310-141907_668046980",
      "dateCreated": "Mar 10, 2017 2:19:07 PM",
      "dateStarted": "Mar 10, 2017 3:57:04 PM",
      "dateFinished": "Mar 10, 2017 3:57:07 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT * from pgene\n",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 3:48:19 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1489176201271_-428479164",
      "id": "20170310-150321_674376494",
      "dateCreated": "Mar 10, 2017 3:03:21 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\nchembl_sparql_iri \u003d \"https://www.ebi.ac.uk/rdf/services/chembl/servlet/query\"\nchembl_sparql_iri \u003d \"https://www.ebi.ac.uk/rdf/services/chembl/sparql\"\nchembl_sparql \u003d SPARQLWrapper2 (chembl_sparql_iri) \n\nquery \u003d Template (\"\"\"\nPREFIX rdf: \u003chttp://www.w3.org/1999/02/22-rdf-syntax-ns#\u003e\nPREFIX rdfs: \u003chttp://www.w3.org/2000/01/rdf-schema#\u003e\nPREFIX owl: \u003chttp://www.w3.org/2002/07/owl#\u003e\nPREFIX dcterms: \u003chttp://purl.org/dc/terms/\u003e\nPREFIX obo: \u003chttp://purl.obolibrary.org/obo/\u003e\nPREFIX sio: \u003chttp://semanticscience.org/resource/\u003e\nPREFIX efo: \u003chttp://www.ebi.ac.uk/efo/\u003e\nPREFIX atlas: \u003chttp://rdf.ebi.ac.uk/resource/atlas/\u003e\nPREFIX atlasterms: \u003chttp://rdf.ebi.ac.uk/terms/atlas/\u003e\nPREFIX biopax3:\u003chttp://www.biopax.org/release/biopax-level3.owl#\u003e\nPREFIX cco: \u003chttp://rdf.ebi.ac.uk/terms/chembl#\u003e\n\nSELECT distinct ?dbXrefProt ?pathwayname ?moleculeLabel ?expressionValue ?propertyValue\nWHERE {\n#Get differentially expressed genes (and proteins) where factor is asthma\n?value atlasterms:pValue ?pvalue .\n?value atlasterms:hasFactorValue ?factor .\n?value rdfs:label ?expressionValue .\n?value atlasterms:isMeasurementOf ?probe .\n?probe atlasterms:dbXref ?dbXrefProt .\n?dbXrefProt a atlasterms:UniprotDatabaseReference .\n?factor atlasterms:propertyType ?propertyType .\n?factor atlasterms:propertyValue ?propertyValue .\n?factor rdf:type efo:EFO_0000270 .\n\n#Compounds target them\nSERVICE \u003chttp://www.ebi.ac.uk/rdf/services/chembl/sparql\u003e {\n  ?act a cco:Activity ;\n    cco:hasMolecule ?molecule ;\n    cco:hasAssay ?assay .\n     ?molecule rdfs:label ?moleculeLabel .\n    ?assay cco:hasTarget ?target .\n    ?target cco:hasTargetComponent ?targetcmpt .\n    ?targetcmpt cco:targetCmptXref ?dbXrefProt .\n    ?targetcmpt cco:taxonomy \u003chttp://identifiers.org/taxonomy/9606\u003e .\n    ?dbXrefProt a cco:UniprotRef .\n}\n\nSERVICE \u003chttp://www.ebi.ac.uk/rdf/services/reactome/sparql\u003e {\n\n  ?protein rdf:type biopax3:Protein .\n  ?protein biopax3:memberPhysicalEntity\n  \t\t[biopax3:entityReference ?dbXrefProt] .\n  ?pathway biopax3:displayName ?pathwayname .\n  ?pathway biopax3:pathwayComponent ?reaction .\n  ?reaction ?rel ?protein\n}\n\n}\n\"\"\")\n\nquery_text \u003d query.substitute ()\nresults \u003d query_sparql (query_text, service\u003dchembl_sparql)\nprint (results.bindings)\n\u0027\u0027\u0027\nfor bind in results.bindings:\n    print (bind)\n    print (\"\"\"dbXrefProt: {0} path: {1} mol: {2} express: {3} prop: {4}\"\"\".format (\n            bind[\u0027dbXrefProt\u0027].value,\n            bind[\u0027pathwayname\u0027].value,\n            bind[\u0027moleculeLabel\u0027].value,\n            bind[\u0027expressionValue\u0027].value,\n            bind[\u0027propertyValue\u0027].value))\n\u0027\u0027\u0027\n    \n    ",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:20:10 PM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/python",
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3887908839584107827.py\", line 346, in \u003cmodule\u003e\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3887908839584107827.py\", line 334, in \u003cmodule\u003e\n    exec(code)\n  File \"\u003cstdin\u003e\", line 49, in \u003cmodule\u003e\n  File \"\u003cstdin\u003e\", line 15, in query_sparql\n  File \"/projects/stars/venv/lib/python2.7/site-packages/SPARQLWrapper/SmartWrapper.py\", line 276, in query\n    res \u003d super(SPARQLWrapper2, self).query()\n  File \"/projects/stars/venv/lib/python2.7/site-packages/SPARQLWrapper/Wrapper.py\", line 567, in query\n    return QueryResult(self._query())\n  File \"/projects/stars/venv/lib/python2.7/site-packages/SPARQLWrapper/Wrapper.py\", line 537, in _query\n    response \u003d urlopener(request)\n  File \"/usr/lib64/python2.7/urllib2.py\", line 154, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/usr/lib64/python2.7/urllib2.py\", line 431, in open\n    response \u003d self._open(req, data)\n  File \"/usr/lib64/python2.7/urllib2.py\", line 449, in _open\n    \u0027_open\u0027, req)\n  File \"/usr/lib64/python2.7/urllib2.py\", line 409, in _call_chain\n    result \u003d func(*args)\n  File \"/usr/lib64/python2.7/urllib2.py\", line 1258, in https_open\n    context\u003dself._context, check_hostname\u003dself._check_hostname)\n  File \"/usr/lib64/python2.7/urllib2.py\", line 1214, in do_open\n    raise URLError(err)\nURLError: \u003curlopen error [Errno 110] Connection timed out\u003e\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872587_872170776",
      "id": "20170222-141155_1338915754",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 10, 2017 2:22:33 PM",
      "dateFinished": "Mar 10, 2017 2:24:41 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom lightning import Lightning\nlightning_host \u003d \"https://stars-lightning.renci.org\"\nlgn \u003d Lightning(host\u003dlightning_host)\nviz \u003d lgn.line([1, 1, 2, 3, 5, 8])\nprint (\"viz id: {}\".format (viz.id))\nprint (\u0027%html \u003ciframe src\u003d\"{0}/visualizations/{1}/iframe\" width\u003d\"400\" height\u003d\"300\" \u003e\u0027.format (lightning_host, viz.id))",
      "user": "ad\\scox",
      "dateUpdated": "Mar 11, 2017 7:49:55 AM",
      "config": {
        "enabled": true,
        "tableHide": false,
        "editorMode": "ace/mode/python",
        "results": {},
        "editorHide": false,
        "editorSetting": {
          "language": "python"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Lightning initialized\nConnected to server at https://stars-lightning.renci.org\nviz id: 949a96ed-c02b-49ce-ad59-75853b0d4024\n"
          },
          {
            "type": "HTML",
            "data": "\u003ciframe src\u003d\"https://stars-lightning.renci.org/visualizations/949a96ed-c02b-49ce-ad59-75853b0d4024/iframe\" width\u003d\"400\" height\u003d\"300\" \u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1488943872587_872170776",
      "id": "20170220-205421_2062798440",
      "dateCreated": "Mar 7, 2017 10:31:12 PM",
      "dateStarted": "Mar 11, 2017 7:49:55 AM",
      "dateFinished": "Mar 11, 2017 7:49:55 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom numpy import random\nmat \u003d random.rand(50,50)\nmat[mat \u003c 0.75] \u003d 0\ngroup \u003d (random.rand(10) * 5).astype(\u0027int\u0027)\n\nlabels\u003d[str(t) for t in range(0,50)]\nviz \u003d lgn.adjacency(mat, group\u003dgroup, labels\u003dlabels, numbers\u003dTrue, sort\u003d\"group\", height\u003d700, width\u003d700)\nprint (\"viz id: {}\".format (viz.id))\nprint (\u0027%html \u003ciframe src\u003d\"{0}/visualizations/{1}/iframe\" width\u003d\"800\" height\u003d\"800\" \u003e\u0027.format (lightning_host, viz.id))\n\n",
      "user": "ad\\scox",
      "dateUpdated": "Mar 11, 2017 9:16:55 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python"
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "viz id: 29528f50-47ff-45cb-b312-a9a39de17fb3\n"
          },
          {
            "type": "HTML",
            "data": "\u003ciframe src\u003d\"https://stars-lightning.renci.org/visualizations/29528f50-47ff-45cb-b312-a9a39de17fb3/iframe\" width\u003d\"800\" height\u003d\"800\" \u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1489115707597_-1509094631",
      "id": "20170309-221507_1516042989",
      "dateCreated": "Mar 9, 2017 10:15:07 PM",
      "dateStarted": "Mar 11, 2017 7:58:31 AM",
      "dateFinished": "Mar 11, 2017 7:58:31 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "ad\\scox",
      "dateUpdated": "Mar 10, 2017 2:52:39 PM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1489175559224_-1002054407",
      "id": "20170310-145239_484854501",
      "dateCreated": "Mar 10, 2017 2:52:39 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "NCATSTranslator/Green/BioChemistry",
  "id": "2CAVFFYR3",
  "angularObjects": {
    "2C8PNVW4G:shared_process": [],
    "2C9M4A84U:shared_process": [],
    "2C8JB5J2A:shared_process": [],
    "2C9WWVYVN::2CAVFFYR3": [],
    "2C8UPVAV8:shared_process": [],
    "2CB6QSJQK:shared_process": [],
    "2CB4GRYA4:shared_process": [],
    "2CAZ1XA1G:shared_process": [],
    "2CBGUDB9H:shared_process": [],
    "2C9VT2CHD:shared_process": [],
    "2CBBPS1GQ:shared_process": [],
    "2CAYF7YMG:shared_process": [],
    "2C7NS2RPM:shared_process": [],
    "2CB55MCKF:shared_process": [],
    "2C9P6TDB4:shared_process": [],
    "2C7YD2D51:shared_process": [],
    "2C9UAC7QR:shared_process": [],
    "2C8K1VZ6J:shared_process": [],
    "2CA9JMF94:shared_process": []
  },
  "config": {},
  "info": {}
}